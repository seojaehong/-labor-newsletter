import feedparser
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import anthropic
import os

# Claude API í‚¤ëŠ” GitHub Actionsì˜ Secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°
anthropic_client = anthropic.Anthropic(api_key=os.environ['ANTHROPIC_API_KEY'])

today = datetime.today()
today_str = today.strftime("%Yë…„ %mì›” %dì¼")

def fetch_rss_feed(url):
    feed = feedparser.parse(url)
    news = []
    for entry in feed.entries:
        try:
            published = datetime.strptime(entry.published, '%a, %d %b %Y %H:%M:%S %Z')
        except:
            published = datetime.today()

        if today - published <= timedelta(days=3):
            summary_soup = BeautifulSoup(entry.summary, "html.parser")
            summary_text = summary_soup.get_text().strip()
            news.append({
                "title": entry.title.replace("[.txt]", ""),
                "link": entry.link,
                "published": published.strftime('%Y-%m-%d %H:%M'),
                "summary": summary_text
            })
    return news

def claude_summary_and_implication(content):
    prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ì½ê³ , ì–‘ì‹ì— ë§ì¶° ì‘ì„±í•´ ì£¼ì„¸ìš”.

[í•µì‹¬ ìš”ì•½] (2ë¬¸ì¥ ë‚´ì™¸):
-

[ì‹¤ë¬´ ì‹œì‚¬ì ] (2-3ê°€ì§€):
-

ë‰´ìŠ¤ ë‚´ìš©:
{content}
"""
    response = anthropic_client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=400,
        temperature=0.2,
        system="ë‹¹ì‹ ì€ ë…¸ë™ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ëª…í™•í•˜ê³  ê°„ê²°íˆ ìš”ì•½í•˜ì—¬ ì¸ì‚¬ë…¸ë¬´ ë‹´ë‹¹ìì—ê²Œ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìš”ì•½ì€ ë‘ ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°íˆ, ì‹¤ë¬´ ì‹œì‚¬ì ì€ ì§§ê³  ëª…ë£Œí•œ í˜•íƒœë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”. ê³¼ë„í•˜ê²Œ ê¸¸ì–´ì§€ë©´ (...)ë¡œ ì¶•ì•½í•˜ì§€ ë§ê³  ë¬¸ì¥ì„ ë‹¤ë“¬ì–´ì„œ ì§§ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”.",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.content[0].text.strip()

def generate_newsletter():
    rss_feeds = {
        "ì‚¬ê±´/ì‚¬ê³ ": "https://rss.app/feeds/5wPlBHdpqAJmIchh.xml",
        "ë…¸ë™ì •ì±…": "https://rss.app/feeds/G6EBProFzjCISBt2.xml",
        "ë…¸ë™ì¡°í•©": "https://rss.app/feeds/c9pv5qpCmgYEROxT.xml",
        "ë…¸ì‚¬ê´€ê³„": "https://rss.app/feeds/JaS17kFMTvYda6QG.xml",
        "ë…¸ë™ë²•": "https://rss.app/feeds/YuTCnwc6CzBa5CIR.xml",
        "í•œê²¨ë ˆ ë…¸ë™ë‰´ìŠ¤": "https://rss.app/feeds/teZ7fkbACRalryLf.xml"
    }

    print(f"ğŸ“Œ [ë…¸ë¬´ë²•ì¸ ìœ„ë„ˆìŠ¤ì˜ ì˜¤ëŠ˜ì˜ ë…¸ë™ë²• ë¸Œë¦¬í•‘] ({today_str} ê¸°ì¤€)\n")

    has_articles = False
    for category, url in rss_feeds.items():
        news_items = fetch_rss_feed(url)
        if news_items:
            has_articles = True
            print(f"â–¶ {category}\n")
            for item in news_items[:5]:
                summary_implication = claude_summary_and_implication(item['summary'])
                print(f"ğŸ”¹ {item['title']} (ë°œí–‰ì¼: {item['published']})\n{summary_implication}\n- ë°”ë¡œê°€ê¸°: {item['link']}\n")

    if not has_articles:
        print("í˜„ì¬ ìµœì‹  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.\n")

    print("ğŸ“Œ ì£¼ìš” ì‹¤ë¬´ ì´ìŠˆë§Œ ì—„ì„ í–ˆìŠµë‹ˆë‹¤. ë…¸ë¬´ë²•ì¸ ìœ„ë„ˆìŠ¤ê°€ ì „í•˜ëŠ” ë…¸ë™ë²• ìµœì‹  ì†Œì‹! ì—…ë¬´ì— ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ ì£¼ë³€ì—ë„ ê³µìœ í•´ ì£¼ì„¸ìš”. ğŸ‘")

if __name__ == "__main__":
    generate_newsletter()
